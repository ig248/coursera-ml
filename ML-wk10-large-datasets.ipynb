{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coursera ML - Week 10\n",
    "\n",
    "https://www.coursera.org/learn/machine-learning/home/week/10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML with large datasets\n",
    "\n",
    "E.g. training set size $m = 10^8$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pick random subset of 1000 - is it sufficient to train a model? \n",
    "\n",
    "if $J_{CV}$ approaches $J_{train}$ for small $m$, we don't have a variance problem, and more data inlikely to improve performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing Gradient Descent\n",
    "\n",
    "E.g. linear regression\n",
    "\n",
    "### Gradient descent implementations \n",
    "#### Batch gradient descent: use $m$ examples in each iteration\n",
    "\n",
    "Problem: computing $m$ gradients at once (*batch*) for *each* step\n",
    "\n",
    "#### Stochastic gradient descent: use 1 example in each iteration\n",
    "\n",
    "$J(\\theta) = \\sum_i cost(\\theta, (x^i,y^i))$, with cost term for each example\n",
    "\n",
    "1. randomly shuffle dataset\n",
    "2. perform gradient step one training example at a time, for $i=1\\dots m$\n",
    "\n",
    "#### Mini-batch gradient descent: use $b$ examples in each iteration\n",
    "\n",
    "Better than stochastic if we have efficient vectorization over $b$ examples\n",
    "\n",
    "Now extra parameter $b$ - may need to fit over $b$\n",
    "\n",
    "### Checking for convergence\n",
    "#### Batch gradient descent\n",
    "Plot $J_{train}(\\theta)$ as a function of #iterations\n",
    "#### Stichastic gradient descent\n",
    "Compute \n",
    "$$\\mathrm{cost}\\left(\\theta, (x^i,y^i)\\right) = \\frac{1}{2}\\left(h_\\theta(x^i)-y^i\\right)^2$$\n",
    "\n",
    "before updating $\\theta$\n",
    "\n",
    "Every say 1000 iterations, plot $\\mathrm{cost}\\left(\\theta, (x^i,y^i)\\right)$ averaged over the last 1000 examples processed by algorithm\n",
    "\n",
    "Smaller learning rate $\\alpha$ may get better final value/smaller oscillations\n",
    "\n",
    "Can decrease $\\alpha$ over time to achieve convergence, e.g. $\\alpha = \\frac{c1}{c2 + \\mathrm{iterationNumber}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Online Learning\n",
    "## Example 1\n",
    "\n",
    "Live data, users choose to stay ($y=1$) or leave ($y=0$)\n",
    "\n",
    "Features $x$, want to learn $p(y=1|x;\\theta)$\n",
    "```\n",
    "repeat forever:\n",
    "    get (x,y) corresponding to user\n",
    "    update theta using (x,y)\n",
    "```\n",
    "update step:\n",
    "$\\theta_j = \\theta_j - \\alpha \\left( h_\\theta(x)-y \\right)x_j$ for $j=0,\\dots, n$\n",
    "\n",
    "Update from one example at a time\n",
    "\n",
    "Can adapt to changing user preferences\n",
    "\n",
    "## Example 2\n",
    "Product search (learning to search)\n",
    "\n",
    "User searches \"Android phone 1080p camera\"\n",
    "\n",
    "Have 100 phones in store, will return 10 to user\n",
    "\n",
    "$x$ = feature vector for each phone\n",
    "\n",
    "$y=1$ if user clicks on link, $y=0$ otherwise\n",
    "\n",
    "Learn $p(y=1|x;\\theta)$ = predicted Click-Through Rate (CTR)\n",
    "\n",
    "E.g. special offere, news articles, product recommendation, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce and data parallelism\n",
    "> Jeffrey Dean and Sanjay Ghemawat\n",
    "\n",
    "Sum of functions over the training set\n",
    "\n",
    "Multiple machines/ multiple cores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.0.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
